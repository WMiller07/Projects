{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes={'LocationNo': str}\n",
    "df = pd.read_csv('BuyTitleOfferEval.csv', header=0, dtype=dict_dtypes, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.set_index('CatalogID', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'actual_BuyOfferAmt_r40'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'actual_BuyOfferAmt_r40'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-79ceaa04e81a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actual_TotalBuyOffers_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actual_BuyOfferAmt_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count_ItemsPriced'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred_TotalSuggestedOffers_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred_SuggestedOffer_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count_ItemsPriced'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error_AAD_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred_AAD_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_CatalogAccDays_TrashPenalty_r40'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RSE_AAD_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred_AAD_r40'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_CatalogAccDays_TrashPenalty_r40'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'actual_BuyOfferAmt_r40'"
     ]
    }
   ],
   "source": [
    "df['actual_TotalBuyOffers_r40'] = df['actual_BuyOfferAmt_r40'] * df['count_ItemsPriced']\n",
    "df['pred_TotalSuggestedOffers_r40'] = df['pred_SuggestedOffer_r40'] * df['count_ItemsPriced']\n",
    "df['error_AAD_r40'] = df['pred_AAD_r40'] - df['avg_CatalogAccDays_TrashPenalty_r40']\n",
    "df['RSE_AAD_r40'] = np.sqrt((df['pred_AAD_r40'] - df['avg_CatalogAccDays_TrashPenalty_r40'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CombinedOfferDF(df):\n",
    "    df_All = pd.DataFrame(df['CatalogID'].unique(), columns =['CatalogID'])#Get all unique catalogIDs in df of all offers, set as index\n",
    "    list_OfferCols = [c for c in df.columns if c not in ['CatalogID','LocationNo', 'CatalogBinding', 'count_ItemsPriced', 'count_ItemsSold']]\n",
    "    filt_ChainOffer = df['LocationNo'] == 'Chain'\n",
    "    #Get all location offers\n",
    "    df_All = df_All.merge(df[~filt_ChainOffer], how='left', on='CatalogID') \n",
    "    #Set indices to CatalogID to update all location CatalogIDs with missing offers with chain offers\n",
    "    df_All.set_index('CatalogID', drop=True, inplace=True)\n",
    "    df.set_index('CatalogID', drop=True, inplace=True)\n",
    "    #Set up filters post-reindexing\n",
    "    filt_NoLocOffer = (df_All['pred_SuggestedOffer_r40'].isna())\n",
    "    filt_ChainOffer = df['LocationNo'] == 'Chain'\n",
    "    #Create column to track whether or not an offer is based on location or chain data, defaulting to \"Location\"\n",
    "    df_All['OfferType'] = 'Location'\n",
    "    #Fill in null location offers with chain offers\n",
    "    df_All.loc[filt_NoLocOffer, list_OfferCols] = df[filt_ChainOffer][list_OfferCols]\n",
    "    #Where null location offers were filled, change OfferType to \"Chain\"\n",
    "    df_All.loc[filt_NoLocOffer, 'OfferType'] = 'Chain'\n",
    "    #Reset indices\n",
    "    df_All.reset_index(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    #Drop all columns that still have no associated offers\n",
    "    df_All.drop(df_All[df_All['pred_SuggestedOffer_r40'].isna()].index, inplace=True)\n",
    "    return df_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_Chain = df['LocationNo'] == 'Chain'\n",
    "df_All = create_CombinedOfferDF(df)\n",
    "df_Chain = df[filt_Chain]#.reset_index(drop=True)\n",
    "df_Loc = df[~filt_Chain]#.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Chain['count_ItemsPriced'].sum())\n",
    "print(df_Loc[df_Loc['pred_SuggestedOffer_r40'].isna()]['count_ItemsPriced'].sum())\n",
    "print(df_Loc[~df_Loc['pred_SuggestedOffer_r40'].isna()]['count_ItemsPriced'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PredCompDF(df, minSampleNum, binding='', **kwargs):\n",
    "    list_Bindings = df['CatalogBinding'].unique()\n",
    "    if (binding in list_Bindings) == False:\n",
    "        binding = list_Bindings\n",
    "    else: \n",
    "        binding = [binding]\n",
    "    filt_QtyNPlus= (df['count_ItemsPriced'] >= minSampleNum) & (df['CatalogBinding'].isin(binding))\n",
    "    df_PredCompUngrouped = df[filt_QtyNPlus].reset_index(drop=True)\n",
    "    df_PredComp = df_PredCompUngrouped.groupby(['pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']).sum()[['count_ItemsPriced', 'count_ItemsSold']].reset_index()\n",
    "    return df_PredComp\n",
    "\n",
    "def calc_CatAcc(df, gradeThreshold=0.3, **kwargs):\n",
    "    filt_EqualGrades = df['pred_BuyOfferPct_r40'] == df['actual_BuyOfferPct_r40']\n",
    "    filt_GradeThreshold = df['pred_BuyOfferPct_r40'] >= gradeThreshold\n",
    "    df_AccByGrade = (df[filt_EqualGrades & filt_GradeThreshold]['count_ItemsPriced'].sum() /\n",
    "                     df[filt_GradeThreshold]['count_ItemsPriced'].sum())\n",
    "    return df_AccByGrade\n",
    "\n",
    "def calc_CatAccByGrade(df):\n",
    "    filt_EqualGrades = df['pred_BuyOfferPct_r40'] == df['actual_BuyOfferPct_r40']\n",
    "    df_AccByGrade = pd.DataFrame((df[filt_EqualGrades].groupby('pred_BuyOfferPct_r40').sum()['count_ItemsPriced'] /\n",
    "                     df.groupby('pred_BuyOfferPct_r40').sum()['count_ItemsPriced']))\n",
    "    df_AccByGrade= df_AccByGrade.merge(df.groupby('pred_BuyOfferPct_r40').sum()['count_ItemsPriced'], on='pred_BuyOfferPct_r40').reset_index()\n",
    "    df_AccByGrade.rename(columns={'pred_BuyOfferPct_r40': 'Suggested Offer Grade', 'count_ItemsPriced_x': 'Pct Accuracy', 'count_ItemsPriced_y': 'Total Qty'}, inplace=True)\n",
    "    return df_AccByGrade\n",
    "\n",
    "def calc_CatPredPctsByGrade(df, gradeThreshold=0, **kwargs):\n",
    "    df_PredPctsByGrade = df.merge(df.groupby('pred_BuyOfferPct_r40').sum()['count_ItemsPriced'], on='pred_BuyOfferPct_r40')\n",
    "    df_PredPctsByGrade['pct_ActualGrades'] = df_PredPctsByGrade['count_ItemsPriced_x'] / df_PredPctsByGrade['count_ItemsPriced_y']\n",
    "    df_PredPctsByGrade.rename(columns={'pred_BuyOfferPct_r40': 'Suggested Offer Grade', \n",
    "                                       'actual_BuyOfferPct_r40': 'Actual Grade',\n",
    "                                       'count_ItemsPriced_x': 'Qty Actual Grades',\n",
    "                                       'pct_ActualGrades': 'Pct Actual Grades'}, inplace=True)\n",
    "    filt_GradeThreshold = df_PredPctsByGrade['Suggested Offer Grade'] >= gradeThreshold\n",
    "    return df_PredPctsByGrade[filt_GradeThreshold][['Suggested Offer Grade', 'Actual Grade', 'Qty Actual Grades', 'Pct Actual Grades']]\n",
    "\n",
    "def calc_MRSE(pred, targ):\n",
    "    mrse = np.sqrt(np.mean([((t - p)**2) for (p, t) in zip(pred, targ)]))\n",
    "    return mrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc_MRSE(df_Chain['avg_CatalogAccDays_NR'], df_Chain['pred_AAD_r40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_MRSE(df_Chain['avg_CatalogAccDays_TrashPenalty_r40'], df_Chain['pred_AAD_r40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_MRSE(df_Chain['avg_CatalogAccDays_TrashPenalty_r40'], df_Chain['pred_AAD_r40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_Grade = df_Chain['pred_BuyOfferPct_r40'] > 0\n",
    "filt_QtyThreshold = df_Chain['count_ItemsPriced'] >= 5\n",
    "filt_Binding = df_Chain['CatalogBinding'] == 'General'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_MRSE(df_Chain[filt_Binding & filt_QtyThreshold]['avg_CatalogAccDays_TrashPenalty_r40'], \n",
    "          df_Chain[filt_Binding & filt_QtyThreshold]['pred_AAD_r40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_MRSE(df_Chain[filt_Grade & filt_Binding & filt_QtyThreshold]['avg_CatalogAccDays_TrashPenalty_r40'], \n",
    "          df_Chain[filt_Grade & filt_Binding & filt_QtyThreshold]['pred_AAD_r40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ChainPredComp = create_PredCompDF(df_Chain[filt_Binding], 5)\n",
    "print(calc_CatAcc(df_ChainPredComp, gradeThreshold=0))\n",
    "calc_CatAccByGrade(df_ChainPredComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_CatPredPctsByGrade(df_ChainPredComp, gradeThreshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_actual = df_Chain['actual_BuyOfferPct_r40'] == 0.4\n",
    "filt_pred = df_Chain['pred_BuyOfferPct_r40'] == 0.4\n",
    "filt_accurate = df_Chain['pred_BuyOfferPct_r40'] == df_Chain['actual_BuyOfferPct_r40']\n",
    "\n",
    "df_Chain[filt_accurate & filt_pred]['count_ItemsPriced'].sum() / df_Chain[filt_pred]['count_ItemsPriced'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LocPredComp = create_PredCompDF(df_Loc, 1)\n",
    "print(calc_CatAcc(df_LocPredComp, gradeThreshold=0))\n",
    "calc_CatAccByGrade(df_LocPredComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ConfusionMatrix_Normalized(df):\n",
    "    list_CalcCols = ['count_ItemsPriced', 'pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']\n",
    "    df_calc = df[list_CalcCols].copy()\n",
    "    df_cm = (df_calc.groupby(['pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']).sum()['count_ItemsPriced']/\n",
    "              df_calc.groupby(['pred_BuyOfferPct_r40']).sum()['count_ItemsPriced'])\n",
    "    df_cm = df_cm.unstack('actual_BuyOfferPct_r40').fillna(0).stack('actual_BuyOfferPct_r40').sort_index(ascending=False) #Add zeros where nulls result in no index value, sort the index\n",
    "    idx_order = df_cm.index.levels[0].sort_values(ascending=False)\n",
    "    array_cm = np.array([np.array(df_cm.loc[i]) for i in idx_order])\n",
    "    return array_cm, idx_order\n",
    "\n",
    "def create_ConfusionMatrix(df):\n",
    "    list_CalcCols = ['count_ItemsPriced', 'pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']\n",
    "    df_calc = df[list_CalcCols].copy()\n",
    "    df_cm = (df_calc.groupby(['pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']).sum()['count_ItemsPriced']/\n",
    "              df_calc.sum()['count_ItemsPriced'])\n",
    "    df_cm = df_cm.unstack('actual_BuyOfferPct_r40').fillna(0).stack('actual_BuyOfferPct_r40').sort_index(ascending=False)\n",
    "    idx_order = df_cm.index.levels[0].sort_values(ascending=False)\n",
    "    array_cm = np.array([np.array(df_cm.loc[i]) for i in idx_order])\n",
    "    print('Total accuracy = {:0.2%}'.format(np.trace(array_cm)))\n",
    "    return array_cm, idx_order\n",
    "\n",
    "def plot_ConfusionMatrix(cm, max_C = 0, **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    if max_C == 0:\n",
    "        max_C = max([i for j in cm for i in j])\n",
    "    sns.heatmap(cm, cmap = 'bone', vmin=0, vmax=max_C, annot=True, fmt='.1%', ax=ax)\n",
    "    ax.set_xlabel('Actual Offer %', fontsize=14)\n",
    "    ax.set_ylabel('Predicted Offer %', fontsize=14)\n",
    "    ax.set_xticklabels([ '40%', '30%', '20%', '5%', '0%'])\n",
    "    ax.set_yticklabels(['40%', '30%', '20%', '5%', '0%'])\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 0.2 * max_C, 0.4 * max_C, 0.6 * max_C, 0.8 * max_C, max_C])\n",
    "    cbar.set_ticklabels(['{:0.0%}'.format(p) for p in [0, 0.2 * max_C, 0.4 * max_C, 0.6 * max_C, 0.8 * max_C, max_C]])\n",
    "    #plt.savefig('./r40_ConfMatrix.png')\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_QtyThreshold = df_Chain['count_ItemsPriced'] >= 5\n",
    "filt_Binding = df_Chain['CatalogBinding'] == 'General'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ChainPredComp = create_PredCompDF(df_Chain[filt_Binding], 5)\n",
    "print(calc_CatAcc(df_ChainPredComp, gradeThreshold=0))\n",
    "calc_CatAccByGrade(df_ChainPredComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_ChainQtyThreshold = df_Chain['count_ItemsPriced'] >= 5\n",
    "filt_ChainBinding = df_Chain['CatalogBinding'] == 'General'\n",
    "cm, pcts = create_ConfusionMatrix_Normalized(df_Chain[filt_ChainBinding & filt_ChainQtyThreshold])\n",
    "plot_ConfusionMatrix(cm, max_C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_ChainQtyThreshold = df_Chain['count_ItemsPriced'] >= 5\n",
    "filt_ChainBinding = df_Chain['CatalogBinding'] == 'General'\n",
    "cm, pcts = create_ConfusionMatrix(df_Chain[filt_ChainBinding & filt_ChainQtyThreshold])\n",
    "plot_ConfusionMatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_LocNAPreds = df_Loc['pred_SuggestedOffer_r40'].isna()\n",
    "filt_LocQtyThreshold = df_Loc['count_ItemsPriced'] >= 5\n",
    "filt_LocBinding = df_Loc['CatalogBinding'] == 'General'\n",
    "cm, pcts = create_ConfusionMatrix_Normalized(df_Loc[~filt_LocNAPreds &filt_LocBinding & filt_LocQtyThreshold])\n",
    "plot_ConfusionMatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_AllQtyThreshold = df_All['count_ItemsPriced'] >= 5\n",
    "filt_AllBinding = df_All['CatalogBinding'] == 'General'\n",
    "filt_AllChainOffer = df_All['OfferType'] == 'Chain'\n",
    "cm, pcts = create_ConfusionMatrix(df_All[filt_AllBinding & filt_AllQtyThreshold])\n",
    "plot_ConfusionMatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_AllQtyThreshold = df_All['count_ItemsPriced'] >= 5\n",
    "filt_AllBinding = df_All['CatalogBinding'] == 'General'\n",
    "cm = create_ConfusionMatrix_Normalized(df_All[filt_AllBinding & filt_AllQtyThreshold])\n",
    "plot_ConfusionMatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 + 15.3 + 14.5+4.1+1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_AllQtyThreshold = df_All['count_ItemsPriced'] >= 6\n",
    "filt_AllBinding = df_All['CatalogBinding'] == 'General'\n",
    "cm = create_ConfusionMatrix_Normalized(df_All[filt_AllBinding & filt_AllQtyThreshold])\n",
    "plot_ConfusionMatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_Chain[filt_Binding & filt_QtyThreshold]['actual_BuyOfferAmt_r40'] * \n",
    "       df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum())\n",
    "\n",
    "print((df_Chain[filt_Binding & filt_QtyThreshold]['pred_SuggestedOffer_r40'] * \n",
    "       df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum())\n",
    "\n",
    "print((df_Chain[filt_Binding & filt_QtyThreshold]['actual_BuyOfferAmt_r40'] * \n",
    "       df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum() -\n",
    "     (df_Chain[filt_Binding & filt_QtyThreshold]['pred_SuggestedOffer_r40'] * \n",
    "       df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum())\n",
    "\n",
    "print((df_Chain[filt_Binding & filt_QtyThreshold]['pred_SuggestedOffer_r40'] * \n",
    "       df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum()/\n",
    "     (df_Chain[filt_Binding & filt_QtyThreshold]['actual_BuyOfferAmt_r40'] * \n",
    "      df_Chain[filt_Binding & filt_QtyThreshold]['count_ItemsPriced']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain[filt_Binding].groupby('pred_BuyOfferPct_r40')['actual_TotalBuyOffers_r40', 'pred_TotalSuggestedOffers_r40'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.regplot(df_Chain[filt_Binding & filt_QtyThreshold]['pred_AAD_r40'],\n",
    "            df_Chain[filt_Binding & filt_QtyThreshold]['error_AAD_r40'],\n",
    "            scatter_kws=dict(alpha=0.1),\n",
    "            line_kws=dict(color='grey'))\n",
    "ax.set_xlim([0,5000])\n",
    "ax.set_ylim([-2500,2500])\n",
    "ax.set_xlabel('Predicted Total Day Accumulation w/ Trash Penalty')\n",
    "ax.set_ylabel('Predicted minus Actual Day Accumulation')\n",
    "#plt.savefig('./r40_ContinuousErrorRegPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.regplot(df_Chain[filt_Binding & filt_QtyThreshold]['pred_AAD_r40'],\n",
    "            df_Chain[filt_Binding & filt_QtyThreshold]['RSE_AAD_r40'],\n",
    "            scatter_kws=dict(alpha=0.1),\n",
    "            line_kws=dict(color='grey'))\n",
    "ax.set_xlim([0,5000])\n",
    "ax.set_ylim([0,5000])\n",
    "ax.set_xlabel('Predicted Title Day Accumulation w/ Trash Penalty')\n",
    "ax.set_ylabel('Prediction RMSE')\n",
    "#plt.savefig('./r40_ContinuousRSERegPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df_Chain[filt_Binding][['pred_AAD_r40', 'RSE_AAD_r40']]\n",
    "df_plt['pred_AAD_r40'] = round(df_plt['pred_AAD_r40'], 0)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.scatterplot(df_plt.groupby('pred_AAD_r40')['pred_AAD_r40'].mean(),\n",
    "                df_plt.groupby('pred_AAD_r40')['RSE_AAD_r40'].mean(),\n",
    "                ax = ax)\n",
    "ax.set_xlim([0, 500])\n",
    "ax.set_ylim([0, 400])\n",
    "ax.set_xlabel('Predicted Day Accumulation')\n",
    "ax.set_ylabel('Root Mean Squared Error')\n",
    "#plt.savefig('./r40_ContinuousRMSE_500Scale.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df_Chain[filt_Binding][['pred_AAD_r40', 'RSE_AAD_r40']]\n",
    "df_plt['pred_AAD_r40'] = round(df_plt['pred_AAD_r40'], 0)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.scatterplot(df_plt.groupby('pred_AAD_r40')['pred_AAD_r40'].mean(),\n",
    "                df_plt.groupby('pred_AAD_r40')['RSE_AAD_r40'].mean(),\n",
    "                ax = ax)\n",
    "ax.set_xlim([0, 500])\n",
    "ax.set_ylim([0, 500])\n",
    "ax.set_xlabel('Predicted Day Accumulation')\n",
    "ax.set_ylabel('Root Mean Squared Error')\n",
    "#plt.savefig('./r40_ContinuousRMSE_200Scale.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain.groupby('pred_BuyOfferPct_r40')['RSE_AAD_r40'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain.groupby('pred_BuyOfferPct_r40')['RSE_AAD_r40'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot(x='pred_BuyOfferPct_r40', y='RSE_AAD_r40', order=[0.4, 0.3, 0.2, 0.05, 0.0], data=df_Chain[filt_Binding], ax=ax, boxprops=dict(alpha=.5))\n",
    "sns.violinplot(x='pred_BuyOfferPct_r40', y='RSE_AAD_r40', order=[0.4, 0.3, 0.2, 0.05, 0.0], data=df_Chain[filt_Binding], ax=ax)\n",
    "ax.set_ylim(0,2000)\n",
    "ax.set_xlabel('Buy Offer Percetages')\n",
    "ax.set_xticklabels([ '40%', '30%', '20%', '5%', '0%'])\n",
    "ax.set_ylabel('Variance')\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(100))\n",
    "#plt.savefig('./r40_ErrorsByGrade_VioBox.png')\n",
    "ax.set_title('Title Day Accumulation Prediction Error by Grade', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(df_Chain.groupby(['pred_BuyOfferPct_r40', 'actual_BuyOfferPct_r40']).sum()['count_ItemsPriced']/\n",
    " df_Chain.groupby(['pred_BuyOfferPct_r40']).sum()['count_ItemsPriced']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Chain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
